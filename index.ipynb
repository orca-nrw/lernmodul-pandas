{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://pandas.pydata.org/\"><img src=https://pandas.pydata.org/static/img/pandas.svg width=300px alt=\"pandas logo\"></a>\n",
    "\n",
    "# Lernmodul zum Datenimport und zur Datenvorbereitung mit pandas\n",
    "\n",
    "Bei pandas handelt es sich um eine der beliebtesten Python Bibliothek zur Datenanalyse. Diese wird dazu benötigt mit Daten in Form von Tabellen arbeiten zu können. Sie stellt verschiedene Funktionalitäten zum Datenimport, zur Datenanalyse und zur Datenmanipulation zur Verfügung. Mithilfe dieses Lernmoduls soll der grundlegende Umgang mit pandas erlernt und geübt werden. Dabei wird der Fokus auf den Datenimport und die Datenvorbereitung gelegt, indem die dafür zur Verfügung stehenden wichtigsten Funktionalitäten erläutert werden. Häufig sind Erkenntnisse aus den Daten erst nach der Visualisierung der vorbereiteten Daten ersichtlich. Zur Veranschaulichung der erarbeiteten Ergebnisse sind an entsprechenden Stellen Visualisierungen eingefügt. Wie diese erstellten werden ist nicht Teil dieses Lernmoduls. Auch findet keine weitere Analyse der Visualisierung zur Gewinnung von Erkenntnissen statt, da der Fokus dieses Lernmoduls auf dem Umgang mit pandas liegt.\n",
    "\n",
    "**Was ist pandas?**\n",
    "\n",
    "pandas ist eine frei zur Verfügung stehende Bibliothek für die Programmiersprache Python. Der Name pandas leitet sich von dem englischen Begriff panel data (Paneldaten) ab. Dabei handel es sich um Datensätze, die bei der Untersuchung derselben Einheit (z. B. Personen) in mehreren Zeitperioden erhoben werden. Insbesondere zur Datenanalyse und Datenmanipulation bietet es Datenstrukturen und Operationen zur sinnvollen Ergänzung von Python. Dabei sind viele Funktionalitäten vorhanden, die denen von Microsoft Excel oder SQL ähneln. Auch für den Import und Export von Daten bietet pandas die benötigten Funktionalitäten. \n",
    "\n",
    "pandas basiert auf der Bibliothek NumPy. NumPy ist eine Abkürzung für numerisches Python und bietet ein Basispaket für wissenschaftliches Rechnen mit Python. Genau wie pandas steht es frei zur Verfügung. pandas erweitert NumPy dabei um weitere Funktionen zur Verarbeitung von Tabellendaten. Die Datenanalyse und -vorbereitung mithilfe von pandas kann zudem durch weitere Bibliotheken sinnvoll ergänzt werden. So können die Ergebnisse der Analyse zum Beispiel durch die Bibliotheken matplotlib oder seaborn anschaulich präsentiert und veranschaulicht werden. Oder mithilfe von scikit-learn oder TensorFlow ein Maschine Learning Modell anhand der aufbereiteten Daten trainiert werden. \n",
    "\n",
    "GitHub: https://github.com/pandas-dev/pandas\n",
    "\n",
    "**Lernziele:**\n",
    "\n",
    "In dieserm Lernmodul werden Grundkenntnisse im Umgang mit der Bibliothek pandas erworben. Die grundlegenden Datenstrukturen in pandas sind bekannt und Daten aus diversen Quellen (z. B. Datenbank, csv-Datei) können importieren und auch wieder exportiert werden. Zudem können Daten untersucht werden und für die weitere Verarbeitung in zum Beispiel Maschine Learning Modellen vorbereitet werden. Dafür werden diverse Methoden zur Bereinigung und zur Transformation der Daten beherrscht, die von pandas zur Verfügung gestellt werden.\n",
    "\n",
    "**Verwendeter Datensatz:**\n",
    "\n",
    "Bei dem Datensatz, der in diesem Lernmodul verwendet wird, handelt es sich um TV Shows und Filme die auf Netflix zur Verfügung stehen. Dabei stammen die zuletzt hinzugefügten Titel aus dem Januar 2020. Im Laufe des Lernmoduls wird unter anderem herausgefunden, welche die meist vertretensten Kategorien auf Netflix sind und in welchen Monaten die meisten Titel hinzugefügt werden.\n",
    "\n",
    "Quelle: https://www.kaggle.com/shivamb/netflix-shows\n",
    "\n",
    "**Hinweis:**\n",
    "\n",
    "Die einzelnen Aufgaben und Lernabschnitte bauen aufeinander auf. Aus diesem Grund ist es wichtig diese nacheinander in der richtigen Reihenfolge zu bearbeiten. Anderseits werden die Aufgaben als falsch markiert, da die Lösung auf den vorherigen Abschnitten aufbaut.\n",
    "\n",
    "**Voraussetzungen:**\n",
    "- Grundlegende Python Kenntnisse\n",
    "- SQL Kenntnisse\n",
    "\n",
    "\n",
    "## Übersicht über die Lerninhalte:\n",
    "\n",
    "1. [Grundlagen zu pandas](#1-Grundlagen-zu-pandas)  \n",
    "    1.1 [pandas importieren](#1.1-pandas-importieren)  \n",
    "    1.2 [Erläuterungen der Datenstrukturen](#1.2-Erläuterungen-der-Datenstrukturen)    \n",
    "2. [Daten importieren und extrahieren](#2-Datenimport-und--export)  \n",
    "    2.1 [Importieren von Daten aus einer Datenbank](#2.1-Importieren-von-Daten-aus-einer-Datenbank)  \n",
    "    2.2 [Importieren von Daten aus einer csv Datei](#2.2-Importieren-von-Daten-aus-einer-csv-Datei)  \n",
    "    2.3 [Zusammenführen von Daten](#2.3-Zusammenführen-von-Daten)  \n",
    "    2.4 [Export von Daten in eine Datenbank](#2.4-Export-von-Daten-in-eine-Datenbank)  \n",
    "    2.5 [Export von Daten in eine csv Datei](#2.5-Export-von-Daten-in-eine-csv-Datei)  \n",
    "    2.6 [Zusammenfassung Datenimport und -export](#2.6-Zusammenfassung-Datenimport-und--export)  \n",
    "    2.7 [Übungsteil](#2.7-Übungsteil)  \n",
    "3. [Daten analysieren](#3-Datenanalyse)  \n",
    "    3.1 [Anzeigen der Daten](#3.1-Anzeigen-der-Daten)  \n",
    "    3.2 [Erstellen einer Kopie der Daten](#3.2-Erstellen-einer-Kopie-der-Daten)  \n",
    "    3.3 [Beschreiben der Daten](#3.3-Beschreiben-der-Daten)  \n",
    "    3.4 [Zugriff auf Datenwerte](#3.4-Zugriff-auf-Datenwerte)  \n",
    "    3.5 [Bedingte Auswahl von Daten](#3.5-Bedingte-Auswahl-von-Daten)  \n",
    "    3.6 [Umbenennen von Spaltennamen](#3.6-Umbenennen-von-Spaltennamen)  \n",
    "    3.7 [Datentypen der Spalten](#3.7-Datentypen-der-Spalten)  \n",
    "    3.8 [Sortieren der Daten](#3.8-Sortieren-der-Daten)  \n",
    "    3.9 [Zusammenfassung Datenanalyse](#3.9-Zusammenfassung-Datenanalyse)  \n",
    "    3.10 [Übungsteil](#3.10-Übungsteil)  \n",
    "4. [Daten bereinigen](#4-Datenbereinigung)   \n",
    "    4.1 [Umgang mit fehlenden Werten](#4.1-Umgang-mit-fehlenden-Werten)  \n",
    "    4.2 [Umgang mit Duplikaten](#4.2-Umgang-mit-Duplikaten)  \n",
    "    4.3 [Zusammenfassung Datenbereinigung](#4.3-Zusammenfassung-Datenbereinigung)  \n",
    "    4.4 [Übungsteil](#4.4-Übungsteil)\n",
    "5. [Daten manipulieren](#5-Datenmanipulation)  \n",
    "    5.1 [Manipulation der Datenstruktur](#5.1-Manipulation-der-Datenstruktur)  \n",
    "    5.2 [Manipulation von Daten](#5.2-Manipulation-von-Daten)  \n",
    "    5.3 [Datenwerte mappen](#5.3-Datenwerte-mappen)  \n",
    "    5.4 [Gruppieren von Daten](#5.4-Gruppieren-von-Daten)  \n",
    "    5.5 [Binning von Daten](#5.5-Binning-von-Daten)  \n",
    "    5.6 [One-hot Encoding](#5.6-One-hot-Encoding)  \n",
    "    5.7 [Zusammenfassung Datenmanipulation](#5.7-Zusammenfassung-Datenmanipulation)  \n",
    "    5.8 [Übungsteil](#5.8-Übungsteil)\n",
    "6. [Zusammenfassung](#6-Zusammenfassung)\n",
    "7. [Referenzen](#7-Referenzen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "#from taskreview import LearningModule\n",
    "from taskreview.learning_module import LearningModule\n",
    "\n",
    "# Lernmodul-Instanz erstellen\n",
    "lm = LearningModule('data/lernmodul_pandas.db')\n",
    "\n",
    "import vis_functions as vf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458 ; padding: 5px; \"></div>\n",
    "\n",
    "## 1 Grundlagen zu pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas installieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas kann entweder mit Anaconda/ Miniconda installiert werden oder mithilfe von pip:\n",
    "\n",
    "- Anaconda/ Miniconda: conda install pandas\n",
    "\n",
    "- pip: pip install pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 pandas importieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem pandas installiert wurde, kann es mit folgender Codezeile importiert werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Erläuterungen der Datenstrukturen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da pandas nun erfolgreich importiert wurde sehen wir uns nun einmal die Datenstrukturen an mit denen in pandas gearbeitet wird. Dabei gibt es zwei grundlegende Datenobjekte: den DataFrame und die Series. Im Folgenden werden diese beiden kurz vorgestellt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei einem DataFrame handelt es sich um eine Art von Tabelle. Dabei besteht ein DataFrame aus drei Bestandteilen: Daten, Spalten und Zeilen. Die Daten können von einem beliebigen Datentyp sein (zum Beispiel Integer, String, Date, Float, Boolean, usw.) und werden mithilfe von Spalten und Zeilen gegliedert. Jede Spalte hat einen Spaltennamen und jede Zeile einen Integerwert als Index.\n",
    "\n",
    "In der Praxis werden DataFrames erzeugt, indem Daten aus externen Speichern eingelesen werden. Zu diesen Speichermedien gehören: Datenbanken, csv Dateien und Excel Dateien (siehe Abschnitt [2. Daten importieren und extrahieren](#2-Datenimport-und--export)). DataFrames können allerdings auch aus zum Beispiel Listen oder Dictonaries erzeugt werden. Dafür wird der Konstruktur `pd.DataFrame()` genutzt. Beispielhaft wird dies im Folgenden mithilfe eines Dictonaries gezeigt. Dabei bilden die Keys des Dictionary die Spaltennamen und die Values beinhalten eine Liste mit Einträgen. Bei diesen einzelnen Einträgen handelt es sich um die entsprechenden Zellwerte innerhalb der Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictonary mit Daten\n",
    "data = {'Vorname': ['Max', 'Lisa'], 'Nachname': ['Mustermann', 'Musterfrau'], 'Alter': [20, 23], 'Lieblingsfilm': ['Star Wars', 'Titanic']}\n",
    "\n",
    "# DataFrame aus einem Dictonary erzeugen\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anstatt einer aufsteigenden Nummer als Zeilenbeschriftungen soll in manchen Fällen eine eigene Beschriftung festgelegt werden. Die Liste der Zeilenbeschriftungen wird Index genannt. Mithilfe des `index` Parameters des Konstruktors können eigene Beschriftungen übergeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, index=['Person 1', 'Person 2'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Series ist ein eindimensionaler gelabelter Array, das jegliche Datentypen beinhalten kann. Sie kann als eine einzelne Spalte einer Tabelle angesehen werden. Auch hier können Zeilenbeschriftungen mithilfe des index Parameters hinzugefügt werden. Eine Series hat allerdings keinen Spaltennamen, sondern einen Gesamtnamen. Dieser kann über den Parameter `name` festgelegt werden. Zur Erzeugung einer Series kannn zum Beispiel eine Liste oder ein Dictonary genutzt werden. Im Folgenden wird dies beispielhaft mit einer Liste demonstriert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste mit Daten\n",
    "list = ['Max', 'Lisa', 'Sandra', 'Daniel']\n",
    "# Zeilenbeschriftungen\n",
    "index = ['Person 1', 'Person 2', 'Person 3', 'Person 4']\n",
    "  \n",
    "# Series aus einer Liste erzeugen\n",
    "ser = pd.Series(list, index, name='Vorname')\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458 ; padding: 5px; \"></div>\n",
    "\n",
    "## 2 Datenimport und -export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den meisten Fällen werden Daten nicht händisch erzeugt, wie im vorherigen Abschnitt, sondern es werden Daten genutzt, die bereits existieren. Diese Daten müssen dafür allerdings zunächst importiert werden. Im folgenden Abschnitt wird der Datenimport aus einer Datenbank und einer csv Datei näher betrachtet. Aus den importierten Daten soll ein DataFrame erzeugt werden, um die Daten mit pandas für weitere Schritte vorbereiten zu können. Nachdem diese Vorbereitung stattgefunden hat sollen die Daten zwischengespeichert werden. Dafür wird der Datenexport genauer betrachtet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importieren von Daten aus einer Datenbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Herstellung einer Datenbankverbindung wird das Package SQLAlchemy installiert und dann importiert. Der Vorteil ist, dass sich dadurch diverse verschiedene Datenbanken einbinden lassen. Wie Verbindungen zu den verschiedenen Datenbanken hergestellt werden können, kann <a href=\"https://docs.sqlalchemy.org/en/14/core/engines.html\">hier</a> eingesehen werden. Im Folgenden wird eine SQLite Datenbank verwendet. Um die Verbindung herzustellen, muss der `create_engine()` Funktion des importierten sqlalchemy Package der Pfad zu der Datenbank übergeben werden. Vor dem Datenbankpfad muss `sqlite:///` hinzugefügt werden, damit SQLAlchemy weiß, um welche Datenbank es sich handelt. Um sich nun mit der jeweiligen Datenbank zu verbinden wird auf dem zurückgegebenen `engine` Objekt die Methode `connect()` aufgerufen. Mithilfe der Funktion `read_sql_query()` können nun diverse SQL Abfragen ausgeführt werden. Der Funktion werden dafür die SQL Abfrage und die Datenbankverbindung übergeben. Die abgefragten Daten werden automatisch in einen DataFrame gespeichert. Nach Beendigung der Abfragen sollte die Datenbankverbindung wieder geschlossen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Herstellen der Datenbankverbindung\n",
    "engine = create_engine('sqlite:///data/lernmodul_pandas.db')\n",
    "con = engine.connect()\n",
    "\n",
    "# Auslesen der Daten aus der Datenbank und Speicherung der Daten in einem DataFrame\n",
    "titles_df = pd.read_sql_query('SELECT * from netflix_titles ORDER By show_id', con)\n",
    "\n",
    "# Schließen der Datenbankverbindung\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Verifizieren, dass die Daten importiert und in dem DataFrame gespeichert wurden, können zum Beispiel die ersten Tabellenzeilen ausgegeben werden. Dafür kann die Methode `head()` eines DataFrames genutzt werden. Diese zeigt die ersten 5 Zeilen des DataFrames an.\n",
    "\n",
    "**Aufgabe: Nutze die Methode `head()` eines DataFrames, um den Datenimport zu verifizieren. Die Daten sollten nun in dem DataFrame `titles_df` zur Verfügung stehen. Welchen Titel trägt der Film mit dem Indexwert 2 in der 3. Zeile?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz für Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Importieren von Daten aus einer csv Datei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe der pandas Funktion `read_csv()` können Daten aus einer csv Datei als pandas DataFrame importiert werden. Der Funktion muss dafür nur der Pfad zu der csv Datei übergeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_csv_df = pd.read_csv('data/netflix_titles.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ kann zum Verifizieren zum Beispiel auch die Anzahl der Tabellenzeilen abgefragt werden. Dafür kann die Python Funktion `len()` genutzt werden.\n",
    "\n",
    "**Aufgabe: Nutze die Funktion `len()`, um zu verifizieren, dass Daten importiert wurden und nun in dem DataFrame `titles_csv_df` zur Verfügung stehen. Wie viele Zeilen sind in dem importieren Daten enthalten?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platz für Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Zusammenführen von Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manchmal sind nicht alle Daten in einer einzigen Datenquelle vorhanden. Um denoch alle relevanten Informationen in einem DataFrame vorliegen zu haben, müssen die einzelnen DataFrames mithilfe der `merge()` Methode eines DataFrames zusammengeführt werden. \n",
    "\n",
    "In dem DataFrame `liebingsshow_df` ist jeweils die Lieblingsshow von unterschiedlichen Personen eingetragen. Leider ist aus der ID der Show nicht direkt ersichtlich, um welche es sich genau handelt. Um diese Information zu erhalten muss in dem vorherig erstellten DataFrame `titles_df` nachgesehen werden. In diesem Fall macht es Sinn die beiden DataFrames zu mergen. Damit zwei DataFrames miteinander gemerged werden können ist es wichtig, dass ein eindeutiger Identifier vorliegt, über den die beiden DataFrames verbunden werden können. In dem Beispiel wäre das die Spalte `show_id`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erzeugen des lieblingsshow_df\n",
    "lieblingsshows = {'ID': [1, 2, 3, 4], 'Name': ['Lena', 'Hannah', 'Sam', 'Sebastian'], 'show_id': [80057969, 80117902, 70234439, 70196145]}\n",
    "lieblingsshows_df = pd.DataFrame.from_dict(lieblingsshows)\n",
    "\n",
    "# Mergen der beiden DataFrames\n",
    "## Parameter 'on' - Spaltennamen durch die die beiden DataFrames gemerged werden sollen\n",
    "## Parameter 'how' - auf welche Art und Weise die DataFrames gemerged werden sollen (left, right, outer, inner)\n",
    "merged_df = lieblingsshows_df.merge(titles_df, how= 'left', on='show_id')\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Export von Daten in eine Datenbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden wird gezeigt, wie ein DataFrame als Datenbanktabelle exportiert werden kann. Dafür wird erneut die SQLite Datenbank genutzt. Nachdem die Verbindung zu der Datenbank hergestellt wurde, kann mithilfe der Methode `to_sql()` der jeweilige DataFrame als Datenbanktabelle exportiert werden. Dafür müssen als Parameter der Name der zu erstellenden Datenbanktabelle sowie die Datenbankverbindung übergeben werden. Optional kann zum Beispiel verhindert werden, dass der Index mit exportiert wird. Ein DataFrame kann defaultmäßig nur einmal in dieselbe Datenbanktabelle exportiert werden, d. h. bei der zweiten Ausführung würde eine Exception geworfen werden, weil die Datenbanktabelle bereits existiert. In diesem Fall kann mithilfe des Parameters `if_exist` festgelegt werden, dass die existierende Tabelle überschrieben werden soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herstellen der Datenbankverbindung\n",
    "engine = create_engine('sqlite:///data/lernmodul_pandas.db')\n",
    "con = engine.connect()\n",
    "\n",
    "# Erzeugen einer Datenbanktabelle auf der Basis eines DataFrames\n",
    "merged_df.to_sql('lieblingsshows', con, index = False, if_exists=\"replace\")\n",
    "\n",
    "# Auslesen der Daten aus der Datenbank zur Überprüfung, ob die Tabelle erstellt wurde\n",
    "db_export_df = pd.read_sql_query('SELECT * from lieblingsshows', con)\n",
    "\n",
    "# Schließen der Datenbankverbindung\n",
    "con.close()\n",
    "\n",
    "db_export_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Export von Daten in eine csv Datei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ können die Daten auch als csv Datei exportiert werden. Hierfür wird die DataFrame Methode `to_csv()` benötigt. Der Methode wird dann der Dateiname der zu erstellenden csv-Datei übergeben. Optional kann auch ein Dateipfad angegeben werden, wenn die Datei nicht in dem aktuellen Verzeichnis erstellt werden soll. Mithilfe des Parameters `index` kann festgelegt werden, ob der Index des DataFrames mit exportiert werden soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export des DataFrames als csv Datei\n",
    "merged_df.to_csv('data/export_test.csv', index=False)\n",
    "\n",
    "# Import der csv Datei, um die Erstellung der Datei zu verifizieren\n",
    "csv_export_df = pd.read_csv('data/export_test.csv')\n",
    "\n",
    "csv_export_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Zusammenfassung Datenimport und -export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/export_import.jpg' alt=\"zusammenfassung datenimport und -export\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFCA00 ; padding: 5px; \"></div>\n",
    "\n",
    "### 2.7 Übungsteil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7.1 Importiere die Spalten `show_id` und `title` aus der Datenbanktabelle `netflix_titles` (Pfad zur Datenbank: data/lernmodul_pandas.db) in einen DataFrame. Nutze dafür die Bibliothek SQLAlchemy, die weiter oben bereits importiert wurde. Speichere den importierten DataFrame in der Variablen `show_titles_df`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "show_titles_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(271, show_titles_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7.2 Lisa, Jan, Dirk und Verena veranstalten einen Filmabend. Jeder von ihnen bringt einen Film dafür mit. Diese Information steht in dem Dictonary `filmabend`. Finde heraus, wie die Filme heißen, die sie mitbringen! Erstelle einen DataFrame mit dem Namen `filmabend_title_df` in dem steht, wer welchen Filmtitle mitbringt. Der DataFrame sollte am Ende wie die folgende Tabelle aufgebaut sein.** \n",
    "\n",
    "<img src='img/table_272.png' width=\"350px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filmabend = {'name': ['Lisa', 'Dirk', 'Jan', 'Verena'], 'show_id': [70077542, 70021648, 80005501, 70248183]}\n",
    "\n",
    "# Hier kommt die Aufgabenlösung hin\n",
    "filmabend_title_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(272, filmabend_title_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.7.3 Exportiere den in Aufgabe 2 entstandenen DataFrame `filmabend_title_df` in die Datanbanktabelle `movie_titles_filmabend` der Datenbank `lernmodul_pandas.db` (Pfad zur Datenbank: data/lernmodul_pandas.db). Der Index des DataFrames soll dabei nicht mit exportiert werden.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "filmabend_title_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(273, filmabend_title_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458 ; padding: 5px; \"></div>\n",
    "\n",
    "## 3 Datenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dem folgenden Abschnitt wird erläutert, wie die Daten eines DataFrames betrachtet werden können. Zudem kann es zur Datenanalyse hilfreich sein, sich zusätzliche Informationen zu den Daten anzeigen zu lassen, zum Beispiel die Lageparameter oder die Anzahl der Spalten und Zeilen. Mithilfe von Bedingungen können bestimmte Zeilen eines DataFrames ausgewählt werden, um einen genaueren Blick auf diese zu werfen. Auch können die Daten nach bestimmten Spalten sortiert werden. Nachdem die Daten genauer betrachtet wurden, kann es hilfreich sein Spaltennamen umzubenennen. Zum Beispiel, wenn die Namen nicht aussagekräftig genug sind. Auch kann es hilfreich sein den Datentyp von Spalten zu ändern, wenn bei der Analyse festgestellt wurde, dass dieser nicht übereinstimmt. Wie all dies in pandas umgesetzt werden kann, schauen wir uns in diesem Abschnitt an. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Anzeigen der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einem Jupyter Notebook kann ein DataFrame einfach angezeigt werden, indem der Name des DataFrames in eine Zelle geschrieben und diese ausgeführt wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den Methoden `head()` und `tail()` können jeweils die ersten oder letzten Datenreihen eines Dataframes angezeigt werden. Defaultmäßig werden 5 Zeilen zurückgegeben. Sollen mehr oder weniger Zeilen angezeigt werden kann die Anzahl der gewünschten Zeilen der Methode als Parameter übergeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Erstellen einer Kopie der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An manchen Stellen kann es sinnvoll sein, eine Kopie des DataFrames zu erstellen, um zum Beispiel die originalen Daten zu behalten bevor die Daten manipuliert werden. Dafür gibt es die Methode `copy()`. Wird die Kopie eines DataFrames bearbeitet werden ausschließlich die Daten der Kopie verändert. Der originale DataFrame bleibt dabei unverändert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df = titles_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Beschreiben der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das `shape` Attribut kann dazu genutzt werden zu schauen, wie groß der DataFrame ist. Unser DataFrame hat 6234 Zeilen und 12 Spalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe der `describe()` Methode können die statistischen Lageparameter des DataFrames angezeigt werden. Dies macht nur Sinn für numerische Daten. Die Funktion kann auf den ganzen DataFrame angewendet werden oder auf einzelne Spalten. Im Falle unserer Daten macht es bei dem aktuellen Stand nur Sinn die Funktion auf die `release_year` Spalte anzuwenden. \n",
    "\n",
    "Bei den Lageparametern handelt es sich um folgende:\n",
    "* count: Die Anzahl der vorhandenen Datenwerte\n",
    "* mean: Durchschnittlicher Datenwert\n",
    "* std: Standardabweichung\n",
    "* min: Kleinster Wert\n",
    "* 25%: 25%-Quantil (mindestens 25% der Daten liegen unter diesem Wert)\n",
    "* 50%: 50%-Quantil, Median\n",
    "* 75%: 75%-Quantil\n",
    "* max: Größter Wert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Welche Erkenntnisse sind durch die `describe` Funktion ersichtlich?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `describe()` Methode kann allerdings auch nützliche Informationen liefern, wenn sie auf eine Spalte mit dem Datentyp String angewandt wird: \n",
    "* count: Anzahl der vorhandenen Werte\n",
    "* unique: Einzigartige Werte\n",
    "* top: Am häufigsten vorkommender Wert\n",
    "* freq: Anzahl der Vorkommen des am häufigsten vorkommenden Wertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df['type'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe der Methode `unique()` können diese einzigartigen Werte auch angezeigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df['type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um zu sehen, wie oft diese einzigartigen Werte in der Spalte vorkommen kann die Methode `value_counts()` genutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_series = titles_df['type'].value_counts()\n",
    "type_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.create_barplot_for_series(type_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Zugriff auf Datenwerte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt verschiedene Möglichkeiten, um auf Datenwerte innerhalb eines DataFrames zuzugreifen. Im folgenden werden die verschiedenen Operatoren kurz vorgestellt. Dazu gehören der Indexing Operator von Python und die pandas Operatoren `iloc` und `loc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Python Indexing Operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um auf die Spalte `title` des `titles_df` zugreifen zu können kann der Indexing Operator `[]` genutzt werden. Die Spalte des DataFrames wird dann als Series zurückgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ kann auf eine Spalte eines DataFrames wie auf ein Attribut zugegriffen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um auf einen spezifischen Wert innerhalb einer Spalte zuzugreifen wird der Indexing Operator `[]` ein weiteres Mal verwendet. Das folgende Beispiel gibt den Title der ersten Netfilx Show im DataFrame aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df['title'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 pandas Operatoren iloc und loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Indexing Operator `[]` aus den vorherigen Beispielen wird von Python bereitgestellt, um die Attribute eines Objektes auszulesen. Wie gezeigt, funktioniert dieser auch mit DataFrames. pandas stellt allerdings auch eigene Operatoren zur Verfügung, mit denen auf die Daten in einem DataFrame zugegriffen werden kann. Diese Operatoren sind `loc` und `iloc`. **Hinweis:** Bei der Verwendung ist zu beachten, dass bei den pandas Operatoren zuerst die Zeilen kommen und dann die Spalten. Beim Python Operator ist es genau anders herum.\n",
    "\n",
    "Bei dem Operator `iloc` basiert die Auswahl der Daten auf ihrer numerischen Position in den Daten. Mit dem Index 0 erhalten wir die Informationen zu dem ersten Titel in den Daten. Hier sprechen wir von einer index-basierten Auswahl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bereits erwähnt werden bei dem pandas Operator `iloc` zunächst die Zeilen betrachtet. Mithilfe eines `:` werden alle Zeilen ausgegeben. Eine bestimmte Spalte kann mithilfe ihres Spaltenindexes ausgegeben werden. In dem folgenden Beispiel werden also alle Zeilen (`:`) der ersten Spalte (`0`) ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die ersten 5 Zeilen der Spalte `titles` auszugeben muss der Spaltenindex `2` verwendet werden, da dies der Position dieser Spalte in dem DataFrame entspricht. Wird `:` in Kombination mit Zahlen verwendet stellt dies immer eine Wertebereich dar. Um die ersten 5 Zeilen auszugeben muss also `:5` eingetragen werden. Was so viel bedeutet wie: Gib mir alle Zeilen bis zu dem Zeilenindex 5 aus. Wobei die Zeile mit dem Index 5 nicht mehr ausgegeben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.iloc[:5,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit negativen Zahlen kann auf die Zeilen am Ende des DataFrames zugegriffen werden. Mit dem Index `-1` wird also die letzte Zeile des DataFrames ausgegeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei dem pandas Operator `loc` basiert die Auswahl der Daten auf den Beschriftungen der Spalten, nicht der Position bzw. des Spaltenindexes in den Daten. Hier sprechen wir von einer label-basierten Auswahl. Die Spalten werden in diesem Fall also nicht über einen Index ausgewählt, sondern indem der Name der Spalte eingefügt wird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.loc[:,'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zudem ist bei der Verwendung von `iloc` und `loc` zu beachten, dass `iloc` bei der Angabe eines Indexbereiches den letzten Index nicht inkludiert. Bei `loc` wird dieser allerdings mit zurückgegeben. Um die ersten drei Zeilen eines DataFrames auszugeben muss also entweder `iloc[:3]` oder `loc[:2]` verwendet werden. Zu diesem Unterschied kommt es, da bei `loc` Spalten durch deren Namen ausgewählt werden können. Hierbei möchte man genau den Bereich der angegebenen Spalten zurück bekommen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe: Welche der folgenden Ausagen sind wahr?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hideInput\n",
    "lm.show_task(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.iloc[2:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Zusammenfassung Operatoren zum Zugriff auf Datenwerte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/indexing_operatoren.jpg' alt=\"Übersicht Indexing Operatoren\" width=\"1100px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Bedingte Auswahl von Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im voherigen Abschnitt haben wir gelernt, wie auf einzelne Spalten, Zeilen oder Zellwerte zugegriffen werden kann. In einige Fällen sollen Daten aufgrund von bestimmten Bedingungen ausgewählt werden. Zum Beispiel wollen wir alle Titel selektieren, die vom `type` ein `Movie` sind. Mithilfe `titles_df['type'] == 'Movie'` wird eine Series ausgegeben, die für jede Zeile angibt, ob es sich um einen `Movie` handelt oder nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df['type'] == 'Movie'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies kann nun mithilfe des Indexing Operators `loc` genutzt werden, um die entsprechenden Zeilen auszugeben, für die die Bedingung zutrifft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.loc[titles_df['type'] == 'Movie'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den Operatoren `&` und `|` können so verschiedene Bedingungen zusammen verwendet werden. Im folgenden Beispiel sollen alle Filme ausgewählt werden, die nach 2018 veröffentlicht wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.loc[(titles_df['type'] == 'Movie') & (titles_df['release_year'] > 2017)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Umbenennen von Spaltennamen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spaltennamen können mit der Methode `rename()` geändert werden. Dieser wir ein Dictonary übergeben, in dem für die zu ändernden Spaltennamen neue Namen angegeben werden. Mithilfe von `inplace = True` werden die Änderungen direkt in den DataFrame übernommen. Die Änderungen müssen also nicht mehr durch `titles_df = ....` in die jeweilige Variable geschrieben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.rename(columns = {'show_id':'id'}, inplace = True) \n",
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Datentypen der Spalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um den Datentyp einer Spalte anzuzeigen wird das Attribut `dtype` verwendet. Durch das Attribut `dtypes` werden die Datentypen jeder Spalte des DataFrames angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.title.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis:** Strings haben in DataFrames nicht ihren eigenen Datentyp, sondern erhalten stattdessen den Datentyp `object`. \n",
    "\n",
    "Mit der Methode `astype()` können die Datentypen der einzelnen Spalten geändert werden. Datumsangaben können mithilfe der pandas Funktion `to_datetime()` in Datetime Objekte konvertiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df['date_added'] = pd.to_datetime(titles_df['date_added'])\n",
    "titles_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Sortieren der Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Daten in einer bestimmten Reihenfolge ausgeben zu können kann die Methode `sort_values()` genutzt werden. In diese wird der Spaltenname hereingegeben, nach der die Daten sortiert werden sollen. Es können auch mehrere Spalten angegeben werden, nach denen sortiert werden soll (`['release_year', 'country']`). Defaultmäßig werden die Daten aufsteigend sortiert. Durch `ascending=False` kann eine absteigende Reihenfolge erreicht werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.sort_values('release_year').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit der Methode `sort_index` kann der DataFrame wieder nach dem Indexwert sortiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.sort_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Zusammenfassung Datenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/datenanalyse.jpg' alt=\"Übersicht Zusammenfassung Datenanalyse\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFCA00 ; padding: 5px; \"></div>\n",
    "\n",
    "### 3.10 Übungsteil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.10.1 Gebe in einer Series an, wie oft die einzelnen Ratings bei den Filmen und TV Shows insgesamt vorkommen. Die Ratings sollen dabei absteigend nach der Anzahl der Vorkommen sortiert werden (Default bei `value_counts()`). Null Werte sollen dabei in der Aufstellung inkludiert sein. Nutze dafür den Parameter `dropna=False` der Methode `value_counts()`. Speichere das Ergebnis in einer Variable mit dem Namen `rating_series` ab.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "rating_series = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(3101, rating_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.create_barplot_for_series(rating_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.10.2 Gebe die Zeilen 5 bis 8 der Spalten `id`, `title` und `release_year` des DataFrames `titles_df` aus. Speichere die selektierten Zeilen in der Variablen `row_selection`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "row_selection = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(3102, row_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.10.3 Gebe in einer Series für jede Jahreszahl aus, wie viele Titel in diesem Jahr veröffentlich wurden (`release_year`). Speichere in der Variablen `release_year_series` nur die Top 5 dieser Series (5 Jahreszahlen, mit den meisten hinzugefügten Titeln).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "release_year_series = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(3103, release_year_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.create_barplot_for_series(release_year_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.10.4 Ein Kind im Alter von 6 Jahre darf nur Filme (`Movie`) mit den Ratings `TV-Y` (Für Kinder zwischen 2 und 6 Jahren) und `G` (Allgemeines Publikum) schauen. Welche der Filme in den Daten dürfte sie schauen? Gebe die Filme in einem DataFrame namens `kinder_filme_df` aus. Der erzeugte DataFrame soll dabei die folgenden Spalten enthalten: `id`, `title`, `date_added`, `release_year`, `rating`, `listed_in`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "kinder_filme_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(3104, kinder_filme_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.10.5 Sortiere die Kinderfilme im DataFrame `kinder_filme_df` absteigend(!) zuerst nach dem Datum, an dem sie hinzugefügt wurden (`date_added`) und danach nach dem Jahr in dem sie erschienen sind (`release_year`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "kinder_filme_sort_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(3105, kinder_filme_sort_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458 ; padding: 5px; \"></div>\n",
    "\n",
    "## 4 Datenbereinigung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem die Daten einer ersten Analyse unterzogen wurden, wird nun beschrieben wie mit fehlenden Werten und Duplikaten in den Daten umgegangen werden kann. Dieser Schritt ist wichtig, um eine gute Qualität der Daten zu gewährleisten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Umgang mit fehlenden Werten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zellen in denen Datenwerte fehlen erhalten immer den Wert `NaN` (Not a Number). Aus technischen  Gründen sind diese `NaN` Werte immer vom Datentyp `float64`. Um die fehlenden Werte eines DataFrames anzuzeigen, wird `pd.isnull()` genutzt. Mit dieser Funktion kann entweder für jede Zelle des gesamten DataFrames oder für jede Zelle einer Spalte angezeigt werden, ob es sich bei dem jeweiligen Zellinhalt um einen `NaN` Wert handelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(titles_df.director)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dies kann dazu genutzt werden, nur die Zeilen anzuzeigen, die in einer bestimmten Spalte `NaN` Werte stehen haben:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df[pd.isnull(titles_df.director)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einen Überblick über die Anzahl der fehlenden Werte je Spalte kann mit `isnull().sum()` angezeigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fehlende Werte können zum Beispiel durch andere ersetzt werden. Hierfür kann die Methode `fillna()` genutzt werden. Dabei können die fehlenden Werte durch einen einzigen Wert ersetzt werden, zum Beispiel wie in diesem Fall durch `Unknown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.director.fillna('Unknown', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun ist für jeden fehlenden Wert der Spalte `director` `Unknown` eingetragen und nicht mehr `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.loc[titles_df['director'] == 'Unknown'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mithilfe von eigenen Funktionen können fehlende Werte auch durch spezifische Werte für jede Zeile ersetzt werden. Das Anwenden von Funktionen wird in [5.3 Datenwerte mappen](#5.3-Datenwerte-mappen) erläutert. \n",
    "\n",
    "Wenn die fehlenden Werte nicht durch sinnvolle Werte ersetzt werden können, sollten die Zeilen mit fehlenden Werten entfernt werden. In unseren Daten ist dies bei der Spalte `date_added` sinnvoll. Dazu kann die Methode `dropna()` genutzt werden. Mithilfe des Parameters `subset` kann das Entfernen der Zeilen auf die `NaN` Werte bestimmter Spalten begrenzt werden. Das heißt, ohne den Parameter würde jede Zeile entfernt werden, die einen NaN Werte beinhaltet (egal in welcher Spalte). Mit dem Parameter werden nur die Zeilen entfernt, die in der angegebenen Spalte (im folgenden Beispiel in der Spalte `date_added`) ein `NaN` Wert stehen haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df = titles_df.dropna(subset=['date_added'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sind die Zeilen mit den `NaN` Werten entfernt, wie das erneute anzeigen der `NaN` Werte pro Spalte zeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In manchen Fällen befinden sich `NaN` Werte auch in einer Spalte, die für die weitere Verarbeitung oder Analyse nicht benötigt wird. Dies muss allerdings im Einzelfall betrachtet und entschieden werden. Dies kann zum Beispiel der Fall sein, wenn die Daten in der Spalte in keinem Zusammenhang zu den restlichen Daten stehen oder ein zufällig fälschlicher Zusammenhang erzeugt wird. Im Abschnitt [5.1 Manipulation der Datenstruktur](#5.1-Manipulation-der-Datenstruktur) wird gezeigt, wie eine Spalte entfernt werden kann. In unserem Fall behalten wir die Spalten `cast` und `country` allerdings in den Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Umgang mit Duplikaten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da sich in dem originalen Datensatz keine Duplikate befinden, wird zu Demonstrationszwecken an dieser Stelle ein Duplikat in den Daten erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_row = titles_df.iloc[-1]\n",
    "\n",
    "movie_tv_duplicat_df = titles_df.append(last_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Duplikate in den Daten zu finden kann die Methode `duplicated()` genutzt werden. Diese zeigt für jede Zeile an, ob sie noch einmal in den Daten vorkommt. Mithilfe der `sum()` Methode kann dann die Anzahl der doppelten Zeilen angezeigt werden. Das erste Vorkommen einer Zeile wird dabei nicht als Duplikat gekennzeichnet, sondern nur alle darauffolgenden weiteren Vorkommen der gleichen Zeile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tv_duplicat_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da in den Daten ein Duplikat erkannt wurde, sollte dieses auch entfernt werden. Bevor das Dulikat in den Daten entfernt wird befinden sich 6224 Zeilen in den Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tv_duplicat_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Entfernen von Duplikaten wird die Methode `drop_duplicates()` benötigt. Mit `inplace=True` kann auch hier angegeben werden, dass die Änderungen in den originalen DataFrame überschrieben werden sollen. Ansonsten werden die Änderungen nicht direkt übernommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tv_duplicat_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem das Duplikat entfernt wurde, befinden sich nur noch 6223 Zeilen in den Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tv_duplicat_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch den Parameter `subset = 'columnName'` kann der Methode `duplicated()` auch eine Spalte übergeben werden, in der nach Duplikaten gesucht werden soll. Im Folgenden werden zum Beispiel alle Shows ausgegeben, deren Titel mindestens doppelt in den Daten vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tv_duplicat_df[movie_tv_duplicat_df.duplicated(subset ='title')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier ist allerdings zu beachten, dass das erste Vorkommen des Titels nicht mit aufgeführt ist. Das es sich bei den oben aufgeführten Titeln um Duplikate handelt wird allerdings klarer, wenn die Daten nach diesen Titeln durchsucht werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_tv_duplicat_df[movie_tv_duplicat_df['title'] == \"Don\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Zusammenfassung Datenbereinigung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/datenbereinigung.jpg' alt=\"Übersicht Zusammenfassung Datenbereinigung\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFCA00 ; padding: 5px; \"></div>\n",
    "\n",
    "### 4.4 Übungsteil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4.1 Zeige alle Filme und TV Shows an, bei denen das `rating` fehlt. Speichere das Ergebnis in der Variablen `missing_ratings`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "missing_ratings = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(441, missing_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4.2 Für Filme und TV Shows die nicht bewertet wurden gibt es zwei Kategorien `NR` für \"Not Rated\" und `UR` für \"Unrated\". In diesem Fall kann es daher sinnvoll sein, diese beiden Kategorien zu einer zusammenzufassen. Außerdem können die Filme und TV Shows, bei denen das Rating fehlt, in die gleiche Kategorie aufgenommen werden. Die Kategorien sollen zu der Kategorie `NR` zusammengefasst werden. Trage nun zunächst für die fehlenden Werte die Kategorie `NR` in der Spalte `ratings` ein.**\n",
    "\n",
    "**Wichtig: Erstelle dafür zunächst einen DataFrame `titles_442`, der eine Kopie des DataFrames `titles_df` darstellt und führe die Änderungen nur an dieser Kopie durch (dadurch geht der ursprüngliche DatFrame bei Fehlern nicht verloren).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "titles_442 = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(442, titles_442)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Ersetzen der Kategorie `UR` wird im Abschnitt [5.2 Manipulation von Daten](#manipulationDaten) durchgeführt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.4.3 In den Daten sind nun immer noch Null Werte in den Spalten `cast` und `country` enthalten. Da diese Spalten für die spätere Analyse noch wichtig sein könnten, sollten nicht die kompletten Spalten entfernt werden. Entferne nur die Zeilen des DataFrames `titles_442`, die noch `NaN` Werte enthalten.** \n",
    "\n",
    "**Wichtig: Erstelle dafür zunächst einen DataFrame `titles_443`, der eine Kopie des DataFrames `titles_442` aus der vorherigen Aufgabe darstellt und führe die Änderungen nur an dieser Kopie durch (dadurch geht der ursprüngliche DatFrame bei Fehlern nicht verloren).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "titles_443 = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(443, titles_443)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #150458 ; padding: 5px; \"></div>\n",
    "\n",
    "## 5 Datenmanipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manchmal sind die Daten nicht direkt in der Form vorhanden, in der wir sie zur weiteren Verarbeitung benötigen. Aus diesem Grund müssen die Daten so angepasst werden, dass später Erkenntnisse aus ihnen gewonnen werden können. Dafür muss eventuell die Datenstruktur des DataFrames angepasst werden. Zum Beispiel werden neue Informationen aus vorhandenen Spalten generiert und in eigenen Spalten dargestellt. Die alten Spalten können in diesem Fall ggf. entfernt werden. Um die Daten später in einem Machine Learning Modell zu verwenden können Techniken wie zum Beispiel One-hot Encoding und Binning hilfreich sein. \n",
    "\n",
    "Für den folgenden Abschnitt werden teilweise zwei zusätzliche DataFrames benötigt. Einen DataFrame, der nur die Filme enthält (`movies_df`) und einen DataFrame, der nur die Serien enthält (`tv_df`). Diese müssen an dieser Stelle zunächst generiert werden. In Abschnitt [3.5 Bedingte Auswahl von Daten](#3.5-Bedingte-Auswahl-von-Daten) wurde bereits erläutert, wie dies funktioniert. Außerdem wird ein neuer DataFrame in `titles_df` geladen, der die Änderungen aus den vorherigen Aufgaben beinhaltet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///data/lernmodul_pandas.db')\n",
    "con = engine.connect()\n",
    "\n",
    "titles_df = pd.read_sql_query('SELECT * from titles_for_section_5', con)\n",
    "titles_df['date_added'] = pd.to_datetime(titles_df['date_added'])\n",
    "con.close()\n",
    "\n",
    "movies_df = titles_df.loc[titles_df['type'] == 'Movie']\n",
    "tv_df = titles_df.loc[titles_df['type'] == 'TV Show']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Manipulation der Datenstruktur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einem DataFrame können beliebig viele Zeilen oder Spalten hinzugefügt werden. Zum Hinzufügen einer Zeile kann die Methode `append()` genutzt werden. Wenn mehrere Zeilen hinzugefügt werden sollen, kann in die Methode ein DataFrame mit den zusätzlichen Zeilen hereingegeben werden. Alternativ können Dictonaries und Listen genutzt werden. Für einzelne Zeilen kann auch ein Series Objekt übergeben werden. Durch den Parameter `ignore_index=True` wird die Zeile einfach an die bestehenden Daten angehängt und erhält den nächsten Indexwert in der Reihe. Die Indexbeschriftung wird dabei bei der Verkettung der Inhalte ignoriert.\n",
    "\n",
    "Wird eine neue Zeile hinzugefügt müssen nicht alle Informationen für diese Zeile bereitgestellt werden. Alle Zellen für die kein Wert vorhanden ist erhalten den Wert `NaN`. Im folgenden Beispiel soll ein neuer Film `new_movie` zu dem bestehenden DataFrame `titles_df` hinzugefügt werden. Für den neuen Film sind allerdings nicht alle Informationen vorhanden, zum Beispiel fehlen die Inhalte für die Spalten `description` und `listed_in`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_movie = pd.DataFrame({'id': [99999999], 'type': ['Movie'], 'title': ['The White Tiger'], 'release_year': [2021], 'duration': ['125 min']})\n",
    "\n",
    "titles_df = titles_df.append(new_movie, ignore_index=True)\n",
    "\n",
    "titles_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der neue Film wurde dem DataFrame `titles_df` nun hinzugefügt, wie der Aufruf von `titles_df.tail()` zeigt.\n",
    "\n",
    "Um eine Zeile aus dem DataFrame zu entfernen wird die Methode `drop()` genutzt. Hierfür muss der Parameter `axis=0` gesetzt werden. Dies bedeutet, dass Zeilen gelöscht werden sollen. \n",
    "\n",
    "**Hinweis:** Bei `axis=1` werden Spalten gelöscht.\n",
    "\n",
    "Der Methode `drop()` wird dann der zu löschende Indexwert hereingegeben. Sollen mehrere Zeilen gelöscht werden können die entsprechenden Indexwerte in Form einer Liste hereingegeben werden. Defaultmäßig wird nach dem Löschen ein neuer DataFrame zurückgegeben. Um den ursprünglichen DataFrame zu ändern muss wieder `inplace=True` hinzugefügt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.drop(5262, axis=0, inplace=True)\n",
    "\n",
    "titles_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der vorher hinzugefügte Film wurde nun wieder aus dem DataFrame `titles_df` entfernt.\n",
    "\n",
    "Eine neue Spalte kann wie folgt erzeugt werden: `titles_df['neuerSpaltenname']`. Wobei für `neuerSpaltenname` der Name der neuen Spalte eingetragen werden sollte. Dieser neuen Spalte müssen allerdings noch Werte zugewiesen werden. Diese können in unterschiedlichster Art und Weise bereitgestellt oder erzeugt werden. Zum Beispiel durch die Methoden `map()` oder `apply()`, die im Abschnitt [5.5 Datenwerte mappen](#5.3-Datenwerte-mappen) vorgestellt werden. Alternativ können die neuen Werte natürlich auch über zum Beispiel Listen zur Verfügung gestellt werden.\n",
    "\n",
    "Im folgenden Beispiel wird eine neue Spalte `years_since_release` erzeugt. Diese soll für jeden Titel das Alter angeben, also die vergangenen Jahre seit dem der Film veröffentlich wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aktuelles_Jahr = 2021\n",
    "\n",
    "titles_df['years_since_release'] = titles_df['release_year'].map(lambda y: aktuelles_Jahr -y)\n",
    "\n",
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um eine Spalte zu entfernen wird erneut die `drop()` Methode genutzt. Nun muss `axis=1` als Parameter hinzugefügt werden. Der Name der zu löschenden Spalte muss auch als Parameter übergeben werden. Alternativ kann auch auch eine Liste mit Spaltennamen übergeben werden, wenn mehrere Spalten gleichzeitig gelöscht werden sollen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.drop('years_since_release', axis=1, inplace=True)\n",
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Manipulation von Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den Abschnitten [3.4 Zugriff auf Datenwerte](#3.4-Zugriff-auf-Datenwerte) und [3.5 Bedingte Auswahl von Daten](#3.5-Bedingte-Auswahl-von-Daten) wurde bereits beschrieben, wie auf verschiedene Datenwerte in einem DataFrame zugegriffen werden kann. Nun sollen Werte geändert werden. Dafür können entweder einzelne Werte oder mehrere gleichzeitg geändert werden. Um mehrere Datenwerte zu ändern sollte auf die Methoden `map()` und `apply()` zurückgegriffen werden. Diese werden im Abschnitt [5.3 Datenwerte mappen](#5.3-Datenwerte-mappen) erläutert. Um einzelne Werte zu verändern kann zunächst eine Zelle ausgewählt werden. Dieser ausgewählten Zelle kann dann ein neuer Wert zugewiesen werden.\n",
    "\n",
    "Im folgenden Beispiel soll der `director` für den Film mit `id = 70234439` gesetzt werden, da dieser in den Daten fehlt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informationen zu dem zu verändernden Film\n",
    "director_transformers_prime = 'David Hartman, Shaunt Nigoghossian, Vinton Heuck, Todd Waterman, Scooter Tidwell, Kirk Van Wormer, Kevin Altieri'\n",
    "show_id_transformers_prime = 70234439\n",
    "\n",
    "# Setzen des Wertes für die Spalte director für den entsprechenden Film\n",
    "titles_df.loc[(titles_df['id'] == show_id_transformers_prime), 'director'] = director_transformers_prime\n",
    "\n",
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Datenwert in einem DataFrame kann auch durch einen anderen ersetzt werden. Diese Funktionalität wird durch die Methode `replace()` bereitgestellt. Als erster Parameter wird der Wert benötigt, der ersetzt werden soll und als zweiter Parameter der neue Wert, mit dem der alte Wert ersetzt werden soll.\n",
    "\n",
    "Im Abschnitt [4.4 Übungsteil](#4-4-Übungsteil) wurden bereits die `NaN` Werte der Spalte `rating` durch `NR` ersetzt. Um nun noch die Kategorien `UR` und `NR` zu vereinigen ersetzen wir im folgenden alle Vorkommen des Ratings `UR` durch das Rating `NR`. Dadurch haben wir nur noch eine Kategorie in der `rating` Spalte die besagt, dass ein Film kein Rating besitzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.rating.replace('UR', 'NR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Datenwerte mappen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manchmal müssen Datenwerte in ein anderes Format gebracht werden oder es soll eine neue Spalte mittels Berechnungen erzeugt werden. Hierbei unterstützen die Methoden `map()` und `apply()`. Im Folgenden soll in dem DataFrame `movies_df` eine Spalte erzeugt werden, die die Länge des Films in Minuten angibt und zwar als Integerwert. In dem DataFrame `tv_df` soll die Anzahl der Staffeln als Integerwert vorhanden sein. Dafür kann in beiden Fällen die Spalte `duration` verwendet werden.\n",
    "\n",
    "**Hinweis:** Die beiden Methoden verändern nicht den ursprünglichen DataFrame. Die Änderungen müssen also noch in den entsprechenden DataFrame geschrieben werden.\n",
    "\n",
    "Die Funktion, die an die `map()` Methode übergeben wird, erwartet einen einzelnen Wert und gibt für diesen einen transformierten Wert zurück. Am Ende gibt die `map()` Methode eine Series zurück, in der sich alle transformierten Werte befinden. Mit dieser Series kann eine bestehende Spalte überschrieben oder eine neue Spalte erzeugt werden. Da die `map()` Methode auf einer Spalte des DataFrames `movies_df` aufgerufen wird, wird die lambda Funktion für jede Zelle dieser Spalte ausgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.copy()\n",
    "movies_df['duration'] = movies_df['duration'].map(lambda d: int(d.split()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können auch die Lageparameter für die Spalte `duration` betrachtet werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `apply()` Methode kann genauso genutzt werden, wie die `map()` Methode. Anstelle von Lambda Funktionen können auch eigene Funktionen übergeben werden.\n",
    "\n",
    "Im folgenden wird für den DataFrame `tv_df` auch die Spalte`duration` überarbeitet. Diese soll die Anzahl der Staffeln nur noch als Integerwert beinhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_count(value):\n",
    "    return int(value.split()[0])\n",
    "\n",
    "tv_df = tv_df.copy()\n",
    "tv_df['duration'] = tv_df['duration'].apply(get_season_count)\n",
    "\n",
    "tv_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der folgenden Grafik sind die vorherig erarbeiteten Ergebnisse nochmal aufbereitet. Das Diagramm zeigt, wie viele TV Shows wie viele Staffeln haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_series = tv_df['duration'].value_counts()\n",
    "vf.create_barplot_for_series(duration_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im vorherigen Beispiel wurde die `apply()` Funktion direkt auf einer Spalte aufgerufen, d. h. das die einzelnen Werte der Spalte an die eigene Funktion hereingegeben werden. Wenn für die Berechnungen allerdings mehrere Werte aus verschiedenen Spalten benötigt werden macht es Sinn, die gesamte Zeile an die eigene Funktion zu übergeben. Um dies zu erreichen, wird die `apply()` Methode auf dem gesamten DataFrame aufgerufen und der Parameter `axis=1` wird gesetzt. \n",
    "\n",
    "Im folgenden Beispiel wird eine Spalte `years_between_add_and_release` erstellt. In dieser Spalte soll die Anzahl der Jahres stehen, die zwischen der Veröffentlichung und des Hinzufügen des Filmes zu Netflix lagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_years_between_added_and_release (row):\n",
    "    year_added = row['date_added'].year\n",
    "    return year_added - row['release_year']\n",
    "\n",
    "movies_df['years_between_add_and_release'] = movies_df.apply(get_years_between_added_and_release, axis=1)\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.create_barplot_for_series(movies_df['years_between_add_and_release'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Grafik zeigt nochmal übersichtlich, wie viele Jahre zwischen der Veröffentlichung und der Verfügbarkeit auf Netflix lagen. In einer ausführlichen Analyse würde man sich die Filme mit einer -1 als Wert in der Spalte `years_between_add_and_release` einmal genauer anschauen. Darauf wird in diesem Lernmodul allerdings nicht weiter eingegangen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Gruppieren von Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In einigen Fällen sollen Daten zunächst gruppiert werden, bevor Operationen auf ihnen ausgeführt werden. In Abschnitt [3.3 Beschreiben der Daten](#3.3-Beschreiben-der-Daten) hatten wir uns mit der Methode `unique()` die einzigartigen Werte der Spalte `type` ausgeben lassen. Die Methode `value_counts()` hatte angezeigt, wie oft diese einzigartigen Werte vorkommen. Im Grunde wurden die Daten hier auch zunächst gruppiert und dann die Anzahl der Vorkommen gezählt. Die folgende Zeile führt zu dem gleichen Ergebnis, wie die Methode `value_counts()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.groupby('type')['type'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Methode `groupby()` gruppiert die Daten nach den Werten der Spalte `type`, also `Movie` und `TV Show`. Aus den gruppierten Daten wird dann die `type` Spalte ausgewählt und gezählt, wie viele Vorkommen dort zu finden sind. \n",
    "\n",
    "Zudem kann nicht nur nach einer Spalte gruppiert werden, sondern nach beliebig vielen Spalten. Dafür werden die Spalten in einem Array an die `groupby` Funktion übergeben. In dem nachfolgenden Beispiel werden die Daten erst nach der Spalte `country` und dann nach der Spalte `type` gruppiert. Für jede Gruppierung wird dann die höchste Jahreszahl ausgewählt, zu der ein Film bzw. eine TV Show veröffentlich wurde. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.groupby(['country','type']).release_year.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Binning von Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim Binning werden die Daten in Klassen eingeteilt. Das bedeutet, dass die vorhandenen Daten in sogenannte 'bins' eingeteilt werden. Dies passiert typischerweise auf der Basis eines Wertebereiches. Im Beispiel von unseren Daten könnte zum Beispiel das Attribut `duration` in Klassen eingeteilt werden. Klassen könnten dabei zum Beispiel sein: 'bis 90 Minuten', 'bis 120 Minuten', 'Überlänge'. Die genaue Anzahl der Minuten wird dann durch die jeweilige Kennung ersetzt. Der Vorteil von Binning ist, dass es dadurch weniger Merkmalsausprägungen gibt. Dadurch kann ein Machine Learning Algorithmus eventuell mit weniger Beispielen trainiert werden, da er weniger Merkmalsauprägungen unterscheiden muss. Ein sehr beliebtes Anwendungsfeld von Binning ist unter anderem die Gruppierung zu Altersgruppen.\n",
    "\n",
    "Zunächst müssen in einer Variablen die Klassen voneinander abgegrenzt werden, d. h. es werden Bins erstellt. Jeder Bin wird durch einen Wertebereich repräsentiert. Diese Wertebereiche werden in der Variablen `bins` gespeichert. Zum Beispiel ist der erste Bin durch den Wertebereich von 0 bis 60 definiert. Das bedeutet, dass alle Filme die in der `duration` Spalte einen Wert bis zu 60 stehen haben in diesen Bin fallen. In einer zweiten Variablen namens `labels` wird für jeden Bin ein Name hinterlegt. Für die ersten Bin wäre das der Name `0-60 Min`. Wenn keine Namen zur Verfügung gestellt werden, wird in der Spalte der Start- und Endwert der jeweiligen Klassen dargestellt. Also zum Beispiel (0,60) für die Klasse, die alle Filme enthält, die eine Länge von 0 bis 60 Minuten haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benötigte Variablen fürs Binning\n",
    "bins = [ 0, 60, 90, 120, 150, 180, 210, 240 ]\n",
    "labels = [ '0-60 Min', '61-90 Min', '91-120 Min','121-150 Min', '151-180 Min', '181-210 Min', '211-240 Min']\n",
    "\n",
    "# Durchfürhung des Binning\n",
    "movies_df['duration_category'] = pd.cut(movies_df['duration'], bins, labels = labels)\n",
    "\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können die Daten anhand der neu erstellten Spalte `duration_category` gruppiert werden, um die Anzahl der Filme in der jeweiligen Kategorie anzuzeigen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_category_series = movies_df['duration_category'].value_counts()\n",
    "vf.create_barplot_for_series(duration_category_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim One-hot Encoding sollen nicht numerische Daten in numerische Daten umgewandelt werden. Im DataFrame `titles_df` kann das Merkmal `type` die Werte `Movie` oder `TV Show` annehmen. Zur weiteren Verarbeitung der Daten in Machine Learning Modellen kann es allerdings sinnvoll sein, diese Repräsentationen durch 0 und 1 zu ersetzen. Das hat den Grund, dass die meisten Algorithmen mit numerischen Daten besser umgehen können.\n",
    "\n",
    "Mit `pd.get_dummies()` erzeugen wir die One-hot Encoding Variablen. Dabei wird für jeden möglichen Wert (in diesem Fall `Movie` und `TV Show`) eine eigene Spalte erzeugt. In der Spalte werden dann die Zeilen mit einer 1 markiert, für die das Merkmal vorhanden ist. Alle anderen erhalten eine 0.\n",
    "\n",
    "Mithilfe `pd.concat()` werden die neu erstellten One-hot Encoding Spalten mit dem bestehenden DataFrame zusammengeführt. Der Parameter `axis=1` zeigt an, dass die beiden Spalten horizontal hinzugefügt werden sollen. Defaultmäßig fügt `pd-concat()` die DataFrames bzw. Series vertikal hinzu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df = pd.concat([titles_df, pd.get_dummies(titles_df['type'])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch One-hot-Encoding wird allerdings auch Redundanz erzeugt, wie in dem Beispiel ersichtlich ist. Wenn eine Titel kein Film ist, dann kann es sich in diesem Fall nur um eine TV Show handelt, da es nur zwei Merkmalsausprägungen gibt. Deswegen macht es in diesem Fall Sinn, eine der beiden entstandenen Spalten zu löschen. Alternativ kann dies auch bei der Erzeugung der One-hot Encoding Variablen mit angegeben werden. Wird der Methode `pd.get_dummies()` der Paramter `drop_first=True` hinzugefügt, wird die erste Variable gelöscht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie in Abschnitt [5.1 Manipulation der Datenstruktur](#5.1-Manipulation-der-Datenstruktur) bereits beschrieben kann eine Spalte mithilfe der Methode `drop()` gelöscht werden. Eine der erzeugten One-hot-Encoding Spalten sollte wieder gelöscht werden. Das gleich gilt für die Spalte `type` da diese nun auch redundant ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.drop('TV Show', axis=1, inplace=True)\n",
    "titles_df.drop('type', axis=1, inplace=True)\n",
    "titles_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7 Zusammenfassung Datenmanipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='img/datenmanipulation.jpg' alt=\"Übersicht Zusammenfassung Datenmanipulation\" width=\"1000px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFCA00 ; padding: 5px; \"></div>\n",
    "\n",
    "### 5.8 Übungsteil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die folgenden Aufgaben sollten jeweils Kopien der entsprechenden DataFrames erstellt werden, bevor Änderungen getätigt werden. Das hat den Grund, dass die Aufgaben unabhängig voneinander bearbeitet werden können."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.8.1 Erstelle eine Kopie des DataFrames `movies_df`. Berechne das Alter der jeweiligen Filme (`movies_df`) ausgehend vom Jahr 2021. Hierfür muss die Spalte `release_year` betrachtet werden. Erstelle für das Alter der jeweiligen Filme eine neue Spalte namens `age`. In einer weiteren Spalte namens `age_group` sollen die Filme nun nach ihrem Alter kategorisiert werden. Dabei sollen folgende Altersklassen mittels Binning gebildet werden:**\n",
    "\n",
    "- 0-5 Jahre\n",
    "- 6-10 Jahre\n",
    "- 11-20 Jahre\n",
    "- 21-30 Jahre\n",
    "- 31-40 Jahre\n",
    "- 41-60 Jahre\n",
    "\n",
    "**Wichtig:** Nutze dafür die folgenden Labels: `labels = [ '0-5', '6-10', '11-20','21-30', '31-40', '41-60', '61-80']`\n",
    "\n",
    "**Am Ende soll in einer Series ausgegeben werden, wie viele Filme sich in den einzelnen Altersklassen befinden (Tipp: Nutze die Methode `value_counts()`). Die Series soll in einer Variablen mit dem Namen `movie_age_series` gespeichert werden.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_to_calculate_from = 2021\n",
    "\n",
    "# Hier kommt die Aufgabenlösung hin\n",
    "movies_copy = movies_df.copy()\n",
    "movie_age_series = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(581, movie_age_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun kann die erstellte Series nochmal als Diagramm angesehen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.create_barplot_for_series(movie_age_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.8.2 Erstelle eine Kopie des DataFrames `movies_df`. Erzeuge in diesem eine neue Spalte `depp_and_over_120Min` die angibt, ob Johnny Depp in einem Film mitgespielt hat und ob der Film mindestens 120 Minuten dauert. Speichere mithilfe dieser neuen Spalte alle Filme, die diese Bedingungen erfüllen, in einem DataFrame `depp_df`. In diesem DataFrame sollen nur die Spalten `id`, `title` und `cast` vorhanden sein.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "movies_copy = movies_df.copy()\n",
    "depp_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(582, depp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.8.3 Was sind die beliebtesten Kategorien? Nutze die Spalte `listed_in` einer Kopie (z. B. `movies_copy`) des DataFrames `movies_df`, um dies herauszufinden. Erstelle ein Dictonary, dass für jede Kategorie die Anzahl der Filme in dieser Kategorie anzeigt. Beachte dabei, dass in der Spalte `listed_in` immer mehrere Kategorien für einen Film stehen. Die einzelnen Kategorien werden hier durch ein Komma getrennt. Erstelle aus dem generierten Dictonary eine Series in der Variablen `category_series` und gebe der Series den Namen `categoryCount` (`series.name = \"categoryCount\"`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryCount = {}\n",
    "\n",
    "# Hier kommt die Aufgabenlösung hin\n",
    "movies_copy = movies_df.copy()\n",
    "category_series = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(583, category_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die erarbeiteten Ergebnisse nochmal besser zu veranschaulichen ist ein Diagramm immer hilfreich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.create_barplot_for_series(category_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.8.4 Gebe in einer Series mit dem Namen `series_date_added` für jedes Jahr an, wie viele der vorhandenen Titel (`titles_df`) in diesem Jahr hinzugefügt wurde (`date_added`). Sortiere die Ergebnisse in der entstandenen Series absteigend (Tipp: `sort_values(ascending=False)`). Der DataFrame `titles_df` muss bei dieser Aufgabe nicht verändert werden.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt die Aufgabenlösung hin\n",
    "series_date_added = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(584, series_date_added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und auch hier nochmal eine grafische Sicht auf die erstellte Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.create_barplot_for_series(series_date_added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.8.5 Erstelle eine Kopie des DataFrames `titles_df`. Gebe für jeden Monat eines jeden Jahres an, wie viele Titel hinzugefügt wurden. Hierfür sollten zunächst zwei neue Spalten erzeugt werden (`year` und `month`) in denen das jeweilige Jahr und der jeweilige Monat aus dem Datum der Spalte `date_added` extrahiert werden sollten. Mithilfe der neu erstellten Spalten kann mittels Gruppierung eine Series `year_month_group` erzeugt werden, die für die vorhandenen Monate und Jahre angibt, wie viele Title hinzugefügt wurden.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt der erste Teil der Aufgabenlösung hin\n",
    "titles_copy = titles_df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mithilfe der Methode `to_frame()` können Series in DataFrames umgewandelt werden. Dies ist an dieser Stelle zur Überprüfung der erstellten Series `year_month_group` nötig. Bitte erzeuge einen DataFrame aus der generierten Series. Die Spaltennamen des DataFrames sollten `year`, `month` und `count` lauten. Benenne ggf. die Spalten um. Danach wird die Methode `reset_index()` auf dem DataFrame aufgerufen, um den Index aus den Spalten `year` und `month` aufzulösen.**\n",
    "\n",
    "**Hinweis: An dieser Stelle ist es wichtig, die Spalten zuerst umzubenennen, bevor die Methode `reset_index()` auf dem DataFrame aufgerufen wird. Mit der Methode `reset_index()` wird der Index bestehend aus den Spalten `year` und `month` aufgelöst und in einfache Spalten konvertiert. Vor der Umbennenung der Spalte `month` ist dies nicht möglich, da es sonst zwei Spalten mit gleicher Beschriftung geben würde.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kommt der zweite Teil der Aufgabenlösung hin\n",
    "year_month_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Aufgabenüberprüfung\n",
    "lm.show_task(585, year_month_df.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die so erstellte Series `year_month_group` kann in einer schicken Heatmap aufbereitet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vf.create_heatmap(year_month_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Zusammenfassung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In diesem Lernmodul wurde der Umgang mit der Bibliothek pandas erläutert. Dafür wurde zunächst im Abschnitt [2 Daten importieren und extrahieren](#2-Datenimport-und--export) der Import von Daten aus einer Datenbank und einer csv Datei besprochen sowie der Export in eine Datenbank und eine csv Datei. Zudem wurde in Abschnitt [3 Daten analysieren](#3-Datenanalyse) gezeigt, wie die auf diese Weise importierten Daten angesehen, analysiert und angepasst (z. B. die Datentypen der Spalten) werden können. Auf den Umgang mit Null Werten und Duplikaten wurden im Abschnitt [4 Daten bereinigen](#4-Datenbereinigung) eingegangen. Zum Schluss wurde im Abschnitt [5 Daten manipulieren](#5-Datenmanipulation) noch die Manipulation der Daten betrachtet, zum Beispiel der Datenstruktur oder Zellwerte. Binning und One-hot-Encoding wurden als sinnvolle Vorbereitung der Daten zur Nutzung in einem Machine Learning Modell vorgestellt. \n",
    "\n",
    "Die Zusammenfassungen der einzelnen Abschnitte können hier nochmal als pdf runtergeladen werden:\n",
    "<a href=\"data/Zusammenfassung_pandas.pdf\">PDF Zusammenfassung öffnen</a> (funktioniert nicht in Chrome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun hast du einen ersten Überblick über die Funktionalitäten erhalten, die pandas zur Datenanalyse und -manipulation bereitstellt und kannst deine neu erworbenen Kenntnisse in pandas bald in der Praxis anwenden und weiter ausbauen.\n",
    "\n",
    "Nach der Arbeit aber erstmal eine wohlverdiente Pause ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"img/panda.jpg\" width=500px alt=\"panda\">\n",
    "</center>\n",
    "<center>\n",
    "    <span>Photo by <a href=\"https://unsplash.com/@zuoanyixi?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Jeremy C</a> on <a href=\"https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>\n",
    "</center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Referenzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://pandas.pydata.org/pandas-docs/stable/reference/index.html\n",
    "* https://www.kaggle.com/learn/pandas\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
